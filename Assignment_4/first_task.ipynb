{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_task.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOtxKVxBZc2NGTN3Qg4AL1V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShidehHashemian/NLP-fall-2020/blob/main/Assignment_4/first_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2-T9yPwRFD-",
        "outputId": "f1a2ea7b-dfeb-4295-a147-9dc7c8cc7f22"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnJzfOdU26-k"
      },
      "source": [
        "**unzip data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8BtzGFD0B7Y",
        "outputId": "e1d0ae8d-2f0e-47e7-8af2-65946b98a0b4"
      },
      "source": [
        "!unzip 'drive/MyDrive/squadv1.zip' -d 'drive/MyDrive/Colab Notebooks/data'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/MyDrive/squadv1.zip\n",
            "   creating: drive/MyDrive/Colab Notebooks/data/squadv1/\n",
            "  inflating: drive/MyDrive/Colab Notebooks/data/squadv1/dev-v1.1.json  \n",
            "  inflating: drive/MyDrive/Colab Notebooks/data/squadv1/train-v1.1.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAS_nxP_3OP8",
        "outputId": "2acd8e48-1c02-4f53-b204-660f4480ed40"
      },
      "source": [
        "import json\r\n",
        "train_data_path = 'drive/MyDrive/Colab Notebooks/data/squadv1/train-v1.1.json'\r\n",
        "with open(train_data_path, 'r') as train_file:\r\n",
        "  # json file is a dictionary with keys 'data' and 'version'\r\n",
        "  data = json.load(train_file)['data']\r\n",
        "  doc_collction = dict()\r\n",
        "  query_answer_collection = {'question':[],\r\n",
        "                             'answer':[],\r\n",
        "                             'paragraph_id':[]}\r\n",
        "  doc_id =0\r\n",
        "  for title_docs in data:\r\n",
        "    # print(title_docs.keys())\r\n",
        "    for doc in title_docs['paragraphs']:\r\n",
        "      doc_collction.update({doc_id:doc['context']})\r\n",
        "      for qas in doc['qas']:\r\n",
        "        # print(qas.__class__)\r\n",
        "        # print(qas.keys())\r\n",
        "        for answer in qas['answers']:\r\n",
        "          query_answer_collection['question'].append(qas['question'])\r\n",
        "          query_answer_collection['answer'].append(answer['text'])\r\n",
        "          query_answer_collection['paragraph_id'].append(doc_id)\r\n",
        "\r\n",
        "          break\r\n",
        "        # print(qas['answers'].__class__)\r\n",
        "        # print(qas['question'].__class__)\r\n",
        "        break\r\n",
        "        # query_answer_collection['query'].append()\r\n",
        "      \r\n",
        "      doc_id+=1\r\n",
        "      \r\n",
        "      # print(doc.keys())\r\n",
        "      # print(len(doc['qas']))\r\n",
        "      break\r\n",
        "    # doc_collection.update({doc_id:doc})\r\n",
        "    break    \r\n",
        "\r\n",
        "  # print(len(train['data'][1]['paragraphs']))\r\n",
        "\r\n",
        "  print(query_answer_collection)\r\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'question': ['To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'What is in front of the Notre Dame Main Building?', 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?', 'What is the Grotto at Notre Dame?', 'What sits on top of the Main Building at Notre Dame?'], 'answer': ['Saint Bernadette Soubirous', 'a copper statue of Christ', 'the Main Building', 'a Marian place of prayer and reflection', 'a golden statue of the Virgin Mary'], 'paragraph_id': [0, 0, 0, 0, 0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0DSRuyRQY-n",
        "outputId": "dc725a70-ce42-4f98-a11f-d59a21d03811"
      },
      "source": [
        "import json\r\n",
        "\r\n",
        "train_data_path = 'drive/MyDrive/Colab Notebooks/data/squadv1/train-v1.1.json'\r\n",
        "\r\n",
        "\r\n",
        "class Answer_SEntence_detector():\r\n",
        "\r\n",
        "  def __init__(self,data_path,k):\r\n",
        "      with open(train_data_path, 'r') as train_file:\r\n",
        "        # json file is a dictionary with keys 'data' and 'version'\r\n",
        "        data = json.load(train_file)['data']\r\n",
        "\r\n",
        "        # a dictionary that wach key is a doc_id and it's value is doc paraghraph text\r\n",
        "        self.doc_collection = dict()\r\n",
        "        # a dictionary that each key has a list ,which are in the same order,\r\n",
        "        # including query's data and answer and question's paraghraph id in order\r\n",
        "        self.query_answer_collection = {'question':[],\r\n",
        "                                        'answer':[],\r\n",
        "                                        'paragraph_id':[]}\r\n",
        "        # use it for indexing paraghraphs\r\n",
        "        doc_id =0\r\n",
        "\r\n",
        "        for title_docs in data:\r\n",
        "          for doc in title_docs['paragraphs']:\r\n",
        "            self.doc_collection.update({doc_id:doc['context']})\r\n",
        "            for qas in doc['qas']:\r\n",
        "              for answer in qas['answers']:\r\n",
        "                self.query_answer_collection['question'].append(qas['question'])\r\n",
        "                self.query_answer_collection['answer'].append(answer['text'])\r\n",
        "                self.query_answer_collection['paragraph_id'].append(doc_id)\r\n",
        "            doc_id+=1\r\n",
        "\r\n",
        "  def preprocess(self,k):\r\n",
        "    doc_id_index =0\r\n",
        "    doc_id =0\r\n",
        "\r\n",
        "    while doc_id < len(self.doc_collection):\r\n",
        "      # print('len:   {}  doc_id:   {}  doc_id_index:   {}'.format(len(self.doc_collection),doc_id,doc_id_index))\r\n",
        "      # chose '. ' char as sentence seperator\r\n",
        "      doc_sentences_len = len(self.doc_collection[doc_id].split('. '))\r\n",
        "      if doc_sentences_len > k:\r\n",
        "        self.doc_collection.pop(doc_id)\r\n",
        "        while self.query_answer_collection['paragraph_id'][doc_id_index]<=doc_id:\r\n",
        "          if self.query_answer_collection['paragraph_id'][doc_id_index]<doc_id:\r\n",
        "            doc_id_index+=1\r\n",
        "          else:\r\n",
        "            self.query_answer_collection['question'].pop(doc_id_index)\r\n",
        "            self.query_answer_collection['answer'].pop(doc_id_index)\r\n",
        "            self.query_answer_collection['paragraph_id'].pop(doc_id_index)\r\n",
        "      \r\n",
        "      doc_id+=1\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# how many sentence each paraghrap includes at most\r\n",
        "k=8\r\n",
        "\r\n",
        "sample = Answer_SEntence_detector(train_data_path,4)\r\n",
        "\r\n",
        "# c=0\r\n",
        "# for doc in sample.doc_collection.keys():\r\n",
        "#   print(doc,doc.__class__)\r\n",
        "#   break\r\n",
        "#   print(doc,'\\n')\r\n",
        "#   break\r\n",
        "# sample.preprocess(k)\r\n",
        "#   c+=1\r\n",
        "#   if c==10:\r\n",
        "#     break\r\n",
        "\r\n",
        "print('data paragraph length:       {}'.format(len(sample.doc_collection)))\r\n",
        "print('questins array lenght:       {}'.format(len(sample.query_answer_collection['question'])))\r\n",
        "print('answers array lenght:        {}'.format(len(sample.query_answer_collection['answer'])))\r\n",
        "print('paragraph_id array lenght:   {}'.format(len(sample.query_answer_collection['paragraph_id'])))\r\n",
        "\r\n",
        "\r\n",
        "sample.preprocess(k)\r\n",
        "print()\r\n",
        "print('data paragraph length:       {}'.format(len(sample.doc_collection)))\r\n",
        "print('questins array lenght:       {}'.format(len(sample.query_answer_collection['question'])))\r\n",
        "print('answers array lenght:        {}'.format(len(sample.query_answer_collection['answer'])))\r\n",
        "print('paragraph_id array lenght:   {}'.format(len(sample.query_answer_collection['paragraph_id'])))\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data paragraph length:       18896\n",
            "questins array lenght:       87599\n",
            "answers array lenght:        87599\n",
            "paragraph_id array lenght:   87599\n",
            "\n",
            "data paragraph length:       17545\n",
            "questins array lenght:       80748\n",
            "answers array lenght:        80748\n",
            "paragraph_id array lenght:   80748\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}