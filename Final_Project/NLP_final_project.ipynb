{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sgQ0_7N1jp6f",
        "9XfWnobRFDxa",
        "8xsMnyjv8Vdi",
        "UGWaEdY4WI_K",
        "9WwoGa1-KUNi",
        "hIKec4WNKwLs",
        "G0Ouci6eK4RJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9lGrmvAz9-y"
      },
      "source": [
        "# Tweets Sentiment analyses on [sentiment140](https://www.kaggle.com/kazanova/sentiment140) dataset\r\n",
        "\r\n",
        "* [link](https://drive.google.com/file/d/1JVWNB8RIqpCdEbO3S7_VOuQ9Xwnlg2oY/view?usp=sharing) to data file on Google Drive\r\n",
        "[link](https://drive.google.com/file/d/1LvKaUEX1cAqPSi3Y5iDU7-44O_zqfB3I/view?usp=sharing) to data zip file on Google Drive\r\n",
        "* [link](https://drive.google.com/file/d/1SuLUgRApiR0xr3aHbBYHqOv6m426u9DA/view?usp=sharing) to Linear classifier file on Google Drive\r\n",
        "[link](https://drive.google.com/drive/folders/1-UxZylzO3cpxitDWrl2UE7nVVT_E4jt-?usp=sharing) to BERT classifier folder on Google Drive\r\n",
        "* [link](https://drive.google.com/file/d/1-0TA272hcn0Cyed3l5mNUYdaFVv7AcSo/view?usp=sharing) to BERT classifier zip file on Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ushSXk_Fli_A"
      },
      "source": [
        "## use below pattern to unzip folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAjz7sLFlh2e"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/desktop1.zip\" -d \"/content/drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnQHIrjWEu96"
      },
      "source": [
        "## Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD68Nw5aE1pM",
        "outputId": "78553030-c240-4c27-af99-e74f64b44710"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgQ0_7N1jp6f"
      },
      "source": [
        "## Installation\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-az1yy1Dhb-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca86837-5788-4b94-9c58-407face053e1"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "\r\n",
        "# Install pickle to save objects's files\r\n",
        "! pip install pickle5\r\n",
        "\r\n",
        "# Install sentence-transformer for vectorizing sentences (used for vectorizing tweets for Linear Classifier)\r\n",
        "!pip install -U sentence-transformers\r\n",
        "\r\n",
        "# To expand contractions\r\n",
        "!pip install contractions\r\n",
        "\r\n",
        "# A dependency of the preprocessing for BERT inputs\r\n",
        "!pip install -q tensorflow-text\r\n",
        "\r\n",
        "# To use adamW optimizer\r\n",
        "!pip install -q tf-models-official"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Collecting pickle5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/5c4dd0462c8d3a6bc4af500a6af240763c2ebd1efdc736fc2c946d44b70a/pickle5-0.0.11.tar.gz (132kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 6.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp36-cp36m-linux_x86_64.whl size=218623 sha256=b33e56534dcdee224e3668ae892de18ee4a7304e30974ae8366ed473ade1c68c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/95/f889ca4aa8b0e0c7f21c8470b6f5d6032f0390a3a141a9a3bd\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n",
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/e2/84d6acfcee2d83164149778a33b6bdd1a74e1bcb59b2b2cd1b861359b339/sentence-transformers-0.4.1.2.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.0MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.1.2-cp36-none-any.whl size=103068 sha256=47a131b8cdb9e1d3fad2a1a81f0adc33cbf9b3bc77dcbee3c86831af186aed4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/33/d1/5703dd56199c09d4a1b41e0c07fb4e7765a84d787cbdc48ac3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=563e5ed0c19f9119d94c6bcdf1366e50d50bc5a3eb033865da1754f6cb6aea90\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.4.1.2 sentencepiece-0.1.95 tokenizers-0.9.4 transformers-4.2.2\n",
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/5f/91102df95715fdda07f56a7eba2baae983e2ae16a080eb52d79e08ec6259/contractions-0.0.45-py2.py3-none-any.whl\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/65/91eab655041e9e92f948cb7302e54962035762ce7b518272ed9d6b269e93/Unidecode-1.1.2-py2.py3-none-any.whl (239kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 7.0MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/92/b3c70b8cf2b76f7e3e8b7243d6f06f7cb3bab6ada237b1bce57604c5c519/pyahocorasick-1.4.1.tar.gz (321kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 12.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.1-cp36-cp36m-linux_x86_64.whl size=84333 sha256=8617f9cfc8adad9aa10d12d99215b750863f8b69cb668ee49ad0b16a56416ae3\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/ab/f7/cb39270df8f6126f3dd4c33d302357167086db460968cfc80c\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: Unidecode, pyahocorasick, textsearch, contractions\n",
            "Successfully installed Unidecode-1.1.2 contractions-0.0.45 pyahocorasick-1.4.1 textsearch-0.0.17\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 8.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 22.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.6MB 71kB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 49.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 54.0MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFR4VXkXpMHb"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0anSr9zcpW-C"
      },
      "source": [
        "import pickle5 as pickle\r\n",
        "\r\n",
        "import re\r\n",
        "import string\r\n",
        "import contractions\r\n",
        "from nltk.corpus import stopwords\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "from sentence_transformers import SentenceTransformer\r\n",
        "from sklearn.linear_model import SGDClassifier\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import torch\r\n",
        "\r\n",
        "\r\n",
        "import shutil\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "import tensorflow_text as text\r\n",
        "from official.nlp import optimization  # to create AdamW optmizer\r\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XfWnobRFDxa"
      },
      "source": [
        "## Constants "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chUFy1pbFG0m"
      },
      "source": [
        "# path to where raw datas are in\r\n",
        "data_path = 'drive/MyDrive/Colab Notebooks/NLP_final_project/data/'\r\n",
        "\r\n",
        "# path to where processed datas are in\r\n",
        "documents_path = 'drive/MyDrive/Colab Notebooks/NLP_final_project/documents/'\r\n",
        "\r\n",
        "csv_file_name = 'training.1600000.processed.noemoticon.csv'\r\n",
        "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\r\n",
        "DATASET_ENCODING = \"ISO-8859-1\"\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# define below const to use it for BERT model \r\n",
        "# sum of TRAIN_SIZE and VAL_SIZE can't be greater than 1280000\r\n",
        "TRAIN_SIZE = 80000\r\n",
        "VAL_SIZE = 20000\r\n",
        "# TEST_SIZE cant be greater than 32000\r\n",
        "TEST_SIZE = 20000\r\n",
        "\r\n",
        "# where linear model is going to be (saved or loaded)\r\n",
        "linear_model_path = os.path.join(documents_path, 'linear_model.pickle')\r\n",
        "# where bert model is going to be (saved or loaded)\r\n",
        "transformer_model_path = os.path.join(documents_path, 'sentiment_bert_classifier')\r\n",
        "\r\n",
        "\r\n",
        "# while max len is 290, 1599514 data among 1600000 data's length is less or equal to 64\r\n",
        "# for training its 1279705 among 1280000 training data\r\n",
        "MAX_LEN = 64\r\n",
        "\r\n",
        "# use this model for vectorizing sentences in SentenceTransformer\r\n",
        "sentence_vectorizing_model = 'stsb-distilbert-base'\r\n",
        "\r\n",
        "# use this model among all expert bert model presented by tensorflow hub as it's\r\n",
        "# recommended for sentiment analysis\r\n",
        "bert_model_name = 'experts/bert/wiki_books/sst2'\r\n",
        "\r\n",
        "\r\n",
        "emoticon_string = r\"\"\"\r\n",
        "    (?:\r\n",
        "      [<>]?\r\n",
        "      [:;=8]                     # eyes\r\n",
        "      [\\-o\\*\\']?                 # optional nose\r\n",
        "      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth      \r\n",
        "      |\r\n",
        "      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\r\n",
        "      [\\-o\\*\\']?                 # optional nose\r\n",
        "      [:;=8]                     # eyes\r\n",
        "      [<>]?\r\n",
        "    )\"\"\"\r\n",
        "\r\n",
        "# The components of the tokenizer:\r\n",
        "regex_strings = (\r\n",
        "    # Phone numbers:\r\n",
        "    r\"\"\"\r\n",
        "    (?:\r\n",
        "      (?:            # (international)\r\n",
        "        \\+?[01]\r\n",
        "        [\\-\\s.]*\r\n",
        "      )?            \r\n",
        "      (?:            # (area code)\r\n",
        "        [\\(]?\r\n",
        "        \\d{3}\r\n",
        "        [\\-\\s.\\)]*\r\n",
        "      )?    \r\n",
        "      \\d{3}          # exchange\r\n",
        "      [\\-\\s.]*   \r\n",
        "      \\d{4}          # base\r\n",
        "    )\"\"\"\r\n",
        "    ,\r\n",
        "    # Emoticons:\r\n",
        "    emoticon_string\r\n",
        "    ,\r\n",
        "    # HTML tags:\r\n",
        "    r\"\"\"<[^>]+>\"\"\"\r\n",
        "    ,\r\n",
        "    # Twitter username:\r\n",
        "    r\"\"\"(?:@[\\w_]+)\"\"\"\r\n",
        "    ,\r\n",
        "    # Twitter hashtags:\r\n",
        "    r\"\"\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\"\"\"\r\n",
        "    ,\r\n",
        "    # Remaining word types:\r\n",
        "    r\"\"\"\r\n",
        "    (?:[a-z][a-z'\\-_]+[a-z])       # Words with apostrophes or dashes.\r\n",
        "    |\r\n",
        "    (?:[+\\-]?\\d+[,/.:-]\\d+[+\\-]?)  # Numbers, including fractions, decimals.\r\n",
        "    |\r\n",
        "    (?:[\\w_]+)                     # Words without apostrophes or dashes.\r\n",
        "    |\r\n",
        "    (?:\\.(?:\\s*\\.){1,})            # Ellipsis dots. \r\n",
        "    |\r\n",
        "    (?:\\S)                         # Everything else that isn't whitespace.\r\n",
        "    \"\"\"\r\n",
        ")\r\n",
        "\r\n",
        "# This is the core tokenizing regex:\r\n",
        "word_re = re.compile(r\"\"\"(%s)\"\"\" % \"|\".join(regex_strings), re.VERBOSE | re.I | re.UNICODE)\r\n",
        "\r\n",
        "# The emoticon string gets its own regex so that we can preserve case for them as needed:\r\n",
        "emoticon_re = re.compile(regex_strings[1], re.VERBOSE | re.I | re.UNICODE)\r\n",
        "\r\n",
        "# These are for regularizing HTML entities to Unicode:\r\n",
        "html_entity_digit_re = re.compile(r\"&#\\d+;\")\r\n",
        "html_entity_alpha_re = re.compile(r\"&\\w+;\")\r\n",
        "amp = \"&amp;\"\r\n",
        "\r\n",
        "# use below dictionaries to get chosen pretrained bert model and proper preprocessor for it \r\n",
        "\r\n",
        "map_name_to_handle = {\r\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\r\n",
        "    'bert_en_cased_L-12_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\r\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\r\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\r\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\r\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\r\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\r\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\r\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\r\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\r\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\r\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\r\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\r\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\r\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\r\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\r\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\r\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\r\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\r\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\r\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\r\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\r\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\r\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\r\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\r\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\r\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\r\n",
        "    'albert_en_base':\r\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\r\n",
        "    'electra_small':\r\n",
        "        'https://tfhub.dev/google/electra_small/2',\r\n",
        "    'electra_base':\r\n",
        "        'https://tfhub.dev/google/electra_base/2',\r\n",
        "    'experts_pubmed':\r\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\r\n",
        "    'experts_wiki_books':\r\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\r\n",
        "    'talking-heads_base':\r\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\r\n",
        "    'experts/bert/wiki_books/sst2':   #use this, as its recommended to use this one for sentiment analysis\r\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/sst2/2',\r\n",
        "}\r\n",
        "\r\n",
        "map_model_to_preprocess = {\r\n",
        "    \r\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'bert_en_cased_L-12_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\r\n",
        "    'albert_en_base':\r\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/2',\r\n",
        "    'electra_small':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'electra_base':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'experts_pubmed':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'experts_wiki_books':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'talking-heads_base':\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "    'experts/bert/wiki_books/sst2':   #use this, as its recommended to use this one for sentiment analysis\r\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xsMnyjv8Vdi"
      },
      "source": [
        "\r\n",
        "##  text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcBfM-fpgnux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5ef459-4378-4100-f6b0-53c9898fee07"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\r\n",
        "stop_words.remove('not')\r\n",
        "\r\n",
        "\r\n",
        "def text_preprocessor(text):\r\n",
        "    \r\n",
        "    # expand contractions\r\n",
        "    text = contractions.fix(' '.join(text.split(' ')))\r\n",
        "    # remove tagged accounts\r\n",
        "    text = ' '.join([token if token[0]!='@'  else '' for token in text.split()])\r\n",
        "\r\n",
        "    # remove URL\r\n",
        "    text = re.sub(r'http\\S+','',text)\r\n",
        "\r\n",
        "    text = text.replace(amp, \" and \")\r\n",
        "    words = word_re.findall(text)\r\n",
        "\r\n",
        "    # Possible alter the case, but avoid changing emoticons like :D into :d:\r\n",
        "    # if not self.preserve_case:\r\n",
        "    # also remove it if it's punctuation (not emoticon)\r\n",
        "    words = map((lambda x: x if emoticon_re.search(x) else x.lower().translate(str.maketrans('', '', string.punctuation))), words)\r\n",
        "    \r\n",
        "    \r\n",
        "\r\n",
        "    # remove stopwords\r\n",
        "    words = [word if word not in stop_words else '' for word in words]\r\n",
        "    # remove redundant spaces\r\n",
        "    text = ' '.join((' '.join(words)).split())\r\n",
        "    \r\n",
        "    text = text.replace('¡', ' ! ')\r\n",
        "\r\n",
        "    return text\r\n",
        "\r\n",
        "  \r\n",
        "# an example of bert_preprocessor\r\n",
        "print('----------------     sample of data normalizer     ------------------')\r\n",
        "\r\n",
        "tweet = 'the next school year is the year for exams can\\'t think about that­ #school #exams #hate'\r\n",
        "print('raw tweet \\n\\t{}'.format(tweet))\r\n",
        "print('text processed tweet: \\n\\t{}'.format(text_preprocessor(tweet)))\r\n",
        "\r\n",
        "tweet = '@switchfoot http://twitpic.com/2y1zl - Awww, that\\'s a bummer.  You shoulda got David Carr of Third Day to do it. ;D'\r\n",
        "print('raw tweet \\n\\t{}'.format(tweet))\r\n",
        "print('text processed tweet: \\n\\t{}'.format(text_preprocessor(tweet)))\r\n",
        "# print(text_preprocessor('i had options i\\'d get it removed i\\'ve never had acne problems'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------     sample of data normalizer     ------------------\n",
            "raw tweet \n",
            "\tthe next school year is the year for exams can't think about that­ #school #exams #hate\n",
            "text processed tweet: \n",
            "\tnext school year year exams not think ­ school exams hate\n",
            "raw tweet \n",
            "\t@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
            "text processed tweet: \n",
            "\tawww bummer shoulda got david carr third day ;D\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGWaEdY4WI_K"
      },
      "source": [
        "## Split data randomely into 2 set of train (80%) and test (20%) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrJD6TsKTgnY",
        "outputId": "c84d8fc2-4126-4c9e-cffd-36e7fbef60ad"
      },
      "source": [
        "# use sklearn train_test_split to randomly split the entire training data into two sets: \r\n",
        "# a train set with 80% of the data and a validation set with 20% of the data\r\n",
        "\r\n",
        "def split_data(csv_data_path):\r\n",
        "  csv_data = pd.read_csv(csv_data_path, encoding =DATASET_ENCODING , names=DATASET_COLUMNS)\r\n",
        "  # [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\r\n",
        "\r\n",
        "  # for each 10 data, assing 8 of them to train, and 2 remained to test\r\n",
        "  data = {'text':[], 'label':[]}\r\n",
        "\r\n",
        "  for index in range(csv_data.shape[0]):\r\n",
        "    # as its a huge file, also preprocess the text before adding them\r\n",
        "    data['text'].append(text_preprocessor(csv_data['text'][index]))\r\n",
        "    data['label'].append(csv_data['target'][index])\r\n",
        "    \r\n",
        "    if index % 100000==0:\r\n",
        "      print('* * {:10s}:{:12d}  {:10s}  {:12d}'.format('processed',index,'over',csv_data.shape[0]))\r\n",
        "\r\n",
        "  \r\n",
        "  text_train, text_test, label_train, label_test = train_test_split(data['text'], data['label'], test_size=0.2, random_state=2020)\r\n",
        "\r\n",
        "  with open(data_path + 'train.pickle', 'wb' ) as train_file:\r\n",
        "    pickle.dump({'label':label_train, 'text': text_train}, train_file, protocol= pickle.HIGHEST_PROTOCOL)\r\n",
        "\r\n",
        "  with open(data_path + 'test.pickle', 'wb' ) as test_file:\r\n",
        "    pickle.dump({'label':label_test, 'text': text_test}, test_file, protocol= pickle.HIGHEST_PROTOCOL)\r\n",
        "\r\n",
        "split_data(data_path + csv_file_name)\r\n",
        "\r\n",
        "with open(data_path + 'train.pickle', 'rb' ) as train_file:\r\n",
        "  train = pickle.load(train_file, encoding = 'utf8')\r\n",
        "  # print(len(train['text']))\r\n",
        "  label = {0:0, 4:0}\r\n",
        "  for l in train['label']:\r\n",
        "    label[l] += 1\r\n",
        "  print(label)\r\n",
        "  # print(len(train['label']))\r\n",
        "with open(data_path + 'test.pickle', 'rb' ) as test_file:\r\n",
        "  test = pickle.load(test_file, encoding= 'utf8')\r\n",
        "  print(test['text'].__class__)\r\n",
        "  label = {0:0, 4:0}\r\n",
        "  for l in test['label']:\r\n",
        "    label[l] += 1\r\n",
        "  print(label)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* * processed :           0  over             1600000\n",
            "* * processed :      100000  over             1600000\n",
            "* * processed :      200000  over             1600000\n",
            "* * processed :      300000  over             1600000\n",
            "* * processed :      400000  over             1600000\n",
            "* * processed :      500000  over             1600000\n",
            "* * processed :      600000  over             1600000\n",
            "* * processed :      700000  over             1600000\n",
            "* * processed :      800000  over             1600000\n",
            "* * processed :      900000  over             1600000\n",
            "* * processed :     1000000  over             1600000\n",
            "* * processed :     1100000  over             1600000\n",
            "* * processed :     1200000  over             1600000\n",
            "* * processed :     1300000  over             1600000\n",
            "* * processed :     1400000  over             1600000\n",
            "* * processed :     1500000  over             1600000\n",
            "{0: 639949, 4: 640051}\n",
            "<class 'list'>\n",
            "{0: 160051, 4: 159949}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8ZpJ58uNHXt"
      },
      "source": [
        "* represent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "RWP8Qxe2NKHu",
        "outputId": "9917f892-1476-405b-8872-918b38eda939"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "import matplotlib.colors as mcolors\r\n",
        "train_count = {'positive': 0, 'negative': 0}\r\n",
        "test_count = {'positive': 0, 'negative': 0}\r\n",
        "\r\n",
        "with open(data_path + 'train.pickle', 'rb') as train_file:\r\n",
        "  train = pickle.load(train_file)\r\n",
        "  for label in train['label']:\r\n",
        "    if label == 0:\r\n",
        "      train_count['negative'] += 1\r\n",
        "    else:\r\n",
        "      train_count['positive'] += 1\r\n",
        "    \r\n",
        "with open(data_path + 'test.pickle', 'rb') as test_file:\r\n",
        "  test = pickle.load(test_file)\r\n",
        "  for label in test['label']:\r\n",
        "    if label == 0:\r\n",
        "      test_count['negative'] += 1\r\n",
        "    else:\r\n",
        "      test_count['positive'] += 1\r\n",
        "# define pie plots input value\r\n",
        "\r\n",
        "x = np.array(list(train_count.values()))\r\n",
        "# a list of colors to be assigned to each condition\r\n",
        "my_colors = ['#029386','#c20078']\r\n",
        "\r\n",
        "fig1, ax1 = plt.subplots()\r\n",
        "# define the plot\r\n",
        "ax1.pie(x, labels=list(train_count.keys()), colors= my_colors, labeldistance= None, wedgeprops = {'edgecolor': 'black'})\r\n",
        "# define legend\r\n",
        "ax1.legend(title=\"training data set:\",bbox_to_anchor=(1.05, 1), loc='upper left')\r\n",
        "\r\n",
        "\r\n",
        "fig2, ax2 = plt.subplots()\r\n",
        "\r\n",
        "x = np.array(list(test_count.values()))\r\n",
        "# define the plot\r\n",
        "ax2.pie(x, labels=list(test_count.keys()), colors= my_colors, labeldistance= None, wedgeprops = {'edgecolor': 'black'})\r\n",
        "# define legend\r\n",
        "ax2.legend(title=\"test data set:\",bbox_to_anchor=(1.05, 1), loc='upper left')\r\n",
        "# show the plot\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkc3ADgPgwBQ"
      },
      "source": [
        "## Linear Classifier:    SVM model using transformers for vectorizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9Am2towO9nB"
      },
      "source": [
        "### Define Linear Classifier\r\n",
        "*   for more details on DistilBERT model used for vectorizing used sentence-transformer represented by [UKPLab](https://github.com/UKPLab/sentence-transformers)\r\n",
        "used 'stsb-distilbert-base' model as it's based on a transformer model and it's been one of the best model considering performance and speed based on the  [given results](https://docs.google.com/spreadsheets/d/14QplCdTCDwEmTqrn1LH4yrbKvdogK4oQvYO1K1aPR5M/edit#gid=0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6t0oxd3PR-x",
        "outputId": "bc04e709-edd8-4f8d-d75a-b744a3980e8b"
      },
      "source": [
        "class LinearClassifier:\r\n",
        "  def __init__(self, train_file_path, test_file_path, model_path= linear_model_path):\r\n",
        "    self.train_path = train_file_path\r\n",
        "    self.test_path = test_file_path\r\n",
        "    # while max len is 290, 1599514 data among 1600000 data's length is less or equal to 64\r\n",
        "    # for training its 1279705 among 1280000 training data\r\n",
        "    self.MAX_LEN = MAX_LEN\r\n",
        "    self.test_chunk_num = 10\r\n",
        "    self.train_chunk_num = 40\r\n",
        "\r\n",
        "    # path to where model has been (or going to be) saved\r\n",
        "    self.save_model_path = model_path\r\n",
        "\r\n",
        "    # path to vectorized train/test data\r\n",
        "    self.train_vectorized_file_path = documents_path + 'vectorized_train_{}.pickle'\r\n",
        "    self.test_vectorized_file_path = documents_path + 'vectorized_test_{}.pickle'\r\n",
        "\r\n",
        "  def vectorizer(self, data_dict= None, query= None, train= True):\r\n",
        "\r\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "    print('current available device is \"{}\" for vectorizing'.format(device))\r\n",
        "    vectorizing_model = SentenceTransformer(sentence_vectorizing_model, device=device)\r\n",
        "\r\n",
        "    if train and query == None:   # vectorizer function has been called for training data\r\n",
        "      tweets_vec = {'vec':list(), 'label': list()}\r\n",
        "      # first calculate number of tweets with length of less than MAX_LEN\r\n",
        "      tweets_count = 0 \r\n",
        "      for doc in data_dict['text']:\r\n",
        "        if len(text_preprocessor(doc).split()) <= self.MAX_LEN:\r\n",
        "          tweets_count += 1\r\n",
        "      \r\n",
        "      \r\n",
        "      # save the vectores in self.train_chunk_num chunks of pickle file as its might not be possible to \r\n",
        "      # feed all of them to model at a same time \r\n",
        "      chunk_size = int(np.floor(tweets_count/self.train_chunk_num))\r\n",
        "      chunk_index = 0\r\n",
        "\r\n",
        "      # use index to count number of tweets that have len <= 64\r\n",
        "      index = 0\r\n",
        "      for doc_id, doc in enumerate(data_dict['text']):\r\n",
        "        if len(doc.split()) <= self.MAX_LEN:\r\n",
        "\r\n",
        "          tweets_vec['vec'].append(vectorizing_model.encode([doc])[0])\r\n",
        "          tweets_vec['label'].append(data_dict['label'][doc_id])\r\n",
        "          index += 1\r\n",
        "          \r\n",
        "        # if its not last chunck and data for saving next chunk has been generated \r\n",
        "        if index % chunk_size == 0 and chunk_index != self.train_chunk_num - 1:\r\n",
        "          # save data with proper name  \r\n",
        "          with open (self.train_vectorized_file_path.format(chunk_index), 'wb') as chunk_file:\r\n",
        "            pickle.dump({'vec': np.array(tweets_vec['vec'][chunk_index * chunk_size:(chunk_index + 1) * chunk_size]), \r\n",
        "                        'label': np.array(tweets_vec['label'][chunk_index * chunk_size:(chunk_index + 1) * chunk_size])\r\n",
        "                        },chunk_file, protocol= pickle.HIGHEST_PROTOCOL)\r\n",
        "          chunk_index += 1\r\n",
        "          print('* saved train {} chunk'.format(chunk_index))\r\n",
        "\r\n",
        "        if index %10000 ==0 and index != 0:\r\n",
        "          print('* vectorizing train tweets * {:10s}:{:12d}  {:10s}  {:12d}'.format('processed',index,'over',tweets_count))\r\n",
        "        \r\n",
        "      # now save last chunks data\r\n",
        "      with open (self.train_vectorized_file_path.format(chunk_index), 'wb') as chunk_file:\r\n",
        "        pickle.dump({'vec': np.array(tweets_vec['vec'][chunk_index * chunk_size:]),\r\n",
        "                     'label': np.array(tweets_vec['label'][chunk_index * chunk_size:])\r\n",
        "                     },chunk_file, protocol= pickle.HIGHEST_PROTOCOL)\r\n",
        "      print('* saved train {} chunk'.format(chunk_index))\r\n",
        "         \r\n",
        "    elif query == None:   # vectorizer function has been called for test data\r\n",
        "      \r\n",
        "      tweets_vec = {'vec':list(), 'label': list()}\r\n",
        "\r\n",
        "      tweets_count = len(data_dict['text'])      \r\n",
        "      chunk_size = int(np.floor(tweets_count/self.test_chunk_num))\r\n",
        "      chunk_index = 0\r\n",
        "\r\n",
        "      for doc_id, doc in enumerate(data_dict['text']):\r\n",
        "        \r\n",
        "        tweets_vec['vec'].append(vectorizing_model.encode([doc])[0])\r\n",
        "        tweets_vec['label'].append(data_dict['label'][doc_id])\r\n",
        "\r\n",
        "        # if its not last chunck and data for saving next chunk has been generated \r\n",
        "        if doc_id % chunk_size == 0 and chunk_index != self.test_chunk_num - 1:\r\n",
        "          # save data with proper name  \r\n",
        "          with open (self.test_vectorized_file_path.format(chunk_index), 'wb') as chunk_file:\r\n",
        "            pickle.dump({'vec': np.array(tweets_vec['vec'][chunk_index * chunk_size:(chunk_index + 1) * chunk_size]), \r\n",
        "                        'label': np.array(tweets_vec['label'][chunk_index * chunk_size:(chunk_index + 1) * chunk_size])\r\n",
        "                        },chunk_file, protocol= pickle.HIGHEST_PROTOCOL)\r\n",
        "          chunk_index += 1\r\n",
        "          print('* saved test {} chunk'.format(chunk_index))\r\n",
        "\r\n",
        "        if doc_id %10000 ==0 and doc_id != 0:\r\n",
        "          print('* vectorizing test tweets * {:10s}:{:12d}  {:10s}  {:12d}'.format('processed',doc_id,'over',tweets_count))\r\n",
        "        \r\n",
        "      # now save last chunks data\r\n",
        "      with open (self.test_vectorized_file_path.format(chunk_index), 'wb') as chunk_file:\r\n",
        "        pickle.dump({'vec': np.array(tweets_vec['vec'][chunk_index * chunk_size:]),\r\n",
        "                     'label': np.array(tweets_vec['label'][chunk_index * chunk_size:])\r\n",
        "                     },chunk_file, protocol= pickle.HIGHEST_PROTOCOL)\r\n",
        "      print('* saved test {} chunk'.format(chunk_index))\r\n",
        "      \r\n",
        "    else: # if its called for a query  \r\n",
        "      return np.array(vectorizing_model.encode([text_preprocessor(query)]))\r\n",
        "  \r\n",
        "  def define_model(self):\r\n",
        "    return SGDClassifier(loss=\"hinge\", penalty=\"l2\")\r\n",
        "\r\n",
        "  def train(self):\r\n",
        "    \r\n",
        "    try:  # try load training data vectorized file\r\n",
        "\r\n",
        "      # to see which training has the best performans while doing croos over and save that one\r\n",
        "      max_accuracy = 0\r\n",
        "      # set 32 chunk for training and 8 chunvk for validation\r\n",
        "      cross_values = [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\r\n",
        "                      [ 32, 33, 34, 35, 36, 37, 38, 39,0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\r\n",
        "                      [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\r\n",
        "                      [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\r\n",
        "                      [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,0, 1, 2, 3, 4, 5, 6, 7]\r\n",
        "                      ]\r\n",
        "      \r\n",
        "      for pattern_id, cross in enumerate(cross_values):\r\n",
        "        # define model\r\n",
        "        model = self.define_model()\r\n",
        "\r\n",
        "        print('{0:160s}'.format(('-'*50) + '  training {:4d} pattern  '.format(pattern_id + 1)+ ('-'*50)))\r\n",
        "        \r\n",
        "        for count, chunk in enumerate(cross[:len(cross) - 8]):\r\n",
        "          # for each chunk of vectorized training data\r\n",
        "          with open(self.train_vectorized_file_path.format(chunk), 'rb') as vectorized_data_file:\r\n",
        "            vectorized_chunk = pickle.load(vectorized_data_file) \r\n",
        "            # learning loap\r\n",
        "            for i in range(1000):\r\n",
        "              model.partial_fit(np.array(vectorized_chunk['vec']),np.array(vectorized_chunk['label']), classes=np.unique(np.array(vectorized_chunk['label'])))\r\n",
        "          \r\n",
        "          print('* training * {:10s}:{:12d}  {:10s}  {:12d}'.format('processed',count + 1,'over',len(cross)))\r\n",
        "\r\n",
        "        print('{0:160s}'.format(('-'*50) + '  validating {:4d} pattern  '.format(pattern_id + 1)+ ('-'*50)))\r\n",
        "        \r\n",
        "        # save model accuracy for evaluation data\r\n",
        "        accuracy_list = list()\r\n",
        "        for count, chunk in enumerate(cross[len(cross) - 8:]):\r\n",
        "          with open(self.train_vectorized_file_path.format(chunk), 'rb') as vectorized_data_file:\r\n",
        "            vectorized_chunk = pickle.load(vectorized_data_file)\r\n",
        "            accuracy_list.append(model.score(np.array(vectorized_chunk['vec']), np.array(vectorized_chunk['label'])))\r\n",
        "          print('* validating * {:10s}:{:12d}  {:10s}  {:12d}'.format('processed',count + 1,'over',len(cross)))\r\n",
        "\r\n",
        "        # calculate avg accuracy\r\n",
        "        avg_accuracy = sum(accuracy_list)/len(accuracy_list)\r\n",
        "        print('{0:160s}'.format(('-'*50) + '  avg accuracy: {:10f}  '.format(avg_accuracy)+ ('-'*50)))\r\n",
        "\r\n",
        "        # update save model\r\n",
        "        if avg_accuracy > max_accuracy:\r\n",
        "          with open(self.save_model_path, 'wb') as model_file:\r\n",
        "            pickle.dump(model, model_file, protocol = pickle.HIGHEST_PROTOCOL)\r\n",
        "          # print('-'*40, 'model updated with accuracy: {:10f}'.format(avg_accuracy), '-'*50)\r\n",
        "          print('{0:160s}'.format(('-'*50) + ' model updated with accuracy: {:10f} '.format(avg_accuracy)+ ('-'*50)))\r\n",
        "          \r\n",
        "          max_accuracy = avg_accuracy \r\n",
        "\r\n",
        "        print('\\n','*'*120,'\\n')\r\n",
        "\r\n",
        "    except IOError:   # vectorize training data as their files are not exist\r\n",
        "      print('-'*10, '\\t vectorized training data files do not exist, prepareing them might take a while\\t', '-'*10)\r\n",
        "      \r\n",
        "      # open training data\r\n",
        "      with open(self.train_path, 'rb') as train_file:\r\n",
        "        train = pickle.load(train_file)\r\n",
        "        # vectorize and store them on disk\r\n",
        "        self.vectorizer(data_dict= train)\r\n",
        "\r\n",
        "      # now that training vectores are on disk, call the training function again\r\n",
        "      self.train()\r\n",
        "\r\n",
        "  def evaluate(self): #evaluate model on test data\r\n",
        "\r\n",
        "    try:  #try to load model\r\n",
        "      with open(self.save_model_path, 'rb') as model_file:\r\n",
        "        model = pickle.load(model_file)\r\n",
        "\r\n",
        "        try:  # try to load vectorized data\r\n",
        "\r\n",
        "          # store predicted labels\r\n",
        "          y_pred = list()\r\n",
        "          # store given labels\r\n",
        "          y_true = list()\r\n",
        "\r\n",
        "          for chunk in range(self.test_chunk_num): \r\n",
        "            # first load vectorized data\r\n",
        "            with open(documents_path + 'vectorized_test_{}.pickle'.format(chunk), 'rb') as vectorized_test_file:\r\n",
        "              vector_dict = pickle.load(vectorized_test_file)\r\n",
        "              # give it's tweets as loaded classifier model predict function to\r\n",
        "              #  get predicted labels as it's output and store them properly\r\n",
        "              y_pred += list(model.predict(vector_dict['vec']))\r\n",
        "              # also store true value for labels\r\n",
        "              y_true += list(vector_dict['label'])\r\n",
        "          \r\n",
        "          # use y_pred and y_true values to evalute classifier model\r\n",
        "          report = classification_report(y_true, y_pred)\r\n",
        "          confusion_mat = confusion_matrix(y_true, y_pred)\r\n",
        "          # return evaluation metrics\r\n",
        "          return report, confusion_mat\r\n",
        "              \r\n",
        "        except: # vectorized data are not exist\r\n",
        "          print('-'*10, '\\t vectorized test data files do not exist, preparing them might take a while\\t', '-'*10)\r\n",
        "          # load test data and fed it to self.vectorizer with train= false to save\r\n",
        "          # vectorized chunk of test data to use it to evalute the classifier\r\n",
        "          with open(self.test_path, 'rb') as test_file:\r\n",
        "            test_data = pickle.load(test_file)\r\n",
        "            # vectorize an save vectores for test data \r\n",
        "            # (as they are too many to store all of them on memory)\r\n",
        "            self.vectorizer(data_dict= test_data, train= False)\r\n",
        "\r\n",
        "            # now that all test data has been vectorized and stored on the disk\r\n",
        "            # recall evaluate function to evaluate model using them\r\n",
        "            self.evaluate()\r\n",
        "   \r\n",
        "    except IOError:   # model file does notexist\r\n",
        "      print('-'*10, '\\t Classier model file does not exist, preparing it might take a while\\t', '-'*10)\r\n",
        "      self.train()\r\n",
        "      self.evaluate()    \r\n",
        "      \r\n",
        "  def query(self, query_text): # classify single sentence\r\n",
        "    # first vectorize query (it'll proprocess text in vectorize function)\r\n",
        "    query_vector = self.vectorizer(query= query_text, train= False)\r\n",
        "    # load the classifier model into memory\r\n",
        "    y_predict = 0\r\n",
        "    try:\r\n",
        "      with open(self.save_model_path, 'rb') as model_file:\r\n",
        "        model = pickle.load(model_file)\r\n",
        "        # now get model prediction for the tweets vector\r\n",
        "        y_predict = model.predict(query_vector)\r\n",
        "    except:\r\n",
        "      print('-'*10, '\\t Classier model file does not exist, preparing it might take a while\\t', '-'*10)\r\n",
        "      self.train()\r\n",
        "      with open(self.save_model_path, 'rb') as model_file:\r\n",
        "        model = pickle.load(model_file)\r\n",
        "        # now get model prediction for the tweets vector\r\n",
        "        y_predict = model.predict(query_vector)\r\n",
        "    # return the result\r\n",
        "    if y_predict == 0:\r\n",
        "      return 'negative'\r\n",
        "    else:\r\n",
        "        return 'positive'\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current available device is \"cuda\" for vectorizing\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245M/245M [00:14<00:00, 16.3MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WwoGa1-KUNi"
      },
      "source": [
        "### Train and Evaluate SVM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig2qAsoHPir-"
      },
      "source": [
        "* Create an object form LinearClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fcYYJOyPppl"
      },
      "source": [
        "train_data_path = os.path.join(data_path, 'train.pickle')\r\n",
        "test_data_path = os.path.join(data_path, 'test.pickle')\r\n",
        "\r\n",
        "svm_model = LinearClassifier(train_data_path, test_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2xaGqrAPvr7"
      },
      "source": [
        "* Train the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM3ChQuGwQ-9"
      },
      "source": [
        "svm_model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vZ8k5rSP9IX"
      },
      "source": [
        "* Evaluate the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_3HJPvaI4lW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807599a0-484d-4f0f-c41c-957e1ceac26a"
      },
      "source": [
        "report, matrix = svm_model.evaluate()\r\n",
        "# print evaluations metrics\r\n",
        "print(report,'\\n', matrix)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.70      0.72    160051\n",
            "           4       0.72      0.76      0.74    159949\n",
            "\n",
            "    accuracy                           0.73    320000\n",
            "   macro avg       0.73      0.73      0.73    320000\n",
            "weighted avg       0.73      0.73      0.73    320000\n",
            " \n",
            " [[112393  47658]\n",
            " [ 39063 120886]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKvE2HpIAQOD"
      },
      "source": [
        "Give a single tweet to classifier to classify it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRiVA6X1ARAl",
        "outputId": "77be8883-44ae-4fb8-8f5b-cff10d754844"
      },
      "source": [
        "tweet = 'safe ways to heal your #acne!! #altwaystoheal #healthy #healing!!'\r\n",
        "# result = f'input: {tweet:<30} : class: {svm_model.query(tweet))}'\r\n",
        "print('{0:<100s}{1:10s}{2:>10s}'.format(tweet,'',svm_model.query(tweet)))\r\n",
        "\r\n",
        "tweet = 'the next school year is the year for exams.ð¯ can\\'t think about that ð­ #school #exams #hate'\r\n",
        "# result = f'input: {tweet:<30} : class: {svm_model.query(tweet))}'\r\n",
        "\r\n",
        "print('{0:<100s}{1:10s}{2:>10s}'.format(tweet,'',svm_model.query(tweet)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "safe ways to heal your #acne!! #altwaystoheal #healthy #healing!!                                               posetive\n",
            "the next school year is the year for exams.ð¯ can't think about that ð­ #school #exams #hate                negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u96PCJjS0Nof"
      },
      "source": [
        "## Transformer:   Classify with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIKec4WNKwLs"
      },
      "source": [
        "### Define DataSequence and BertClassifier classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTtMc4EH0buS"
      },
      "source": [
        "* Define an Sequence object, use it to convert data to batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1GtEDMBH74O"
      },
      "source": [
        "import numpy as np\r\n",
        "import math\r\n",
        "class DataSequence(tf.keras.utils.Sequence):\r\n",
        "\r\n",
        "    def __init__(self, x_set, y_set, batch_size):\r\n",
        "        self.x, self.y = x_set, y_set\r\n",
        "        self.batch_size = batch_size\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return math.ceil(len(self.x) / self.batch_size)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) *\r\n",
        "        self.batch_size]\r\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) *\r\n",
        "        self.batch_size]\r\n",
        "        return (np.array(batch_x),\r\n",
        "                np.array(batch_y))\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-IvHe98CXr0"
      },
      "source": [
        "* BertClassifier class, which use one of [Bert Expert](https://tfhub.dev/google/collections/experts/bert/1)  models which is recommended for sentiment tasks ([wiki_books/sst2](https://tfhub.dev/google/experts/bert/wiki_books/sst2/2))\r\n",
        "* for crossentropy as using from_logits=True may be more numerically stable, define it in this form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFlicFLSIX3R"
      },
      "source": [
        "import math\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "\r\n",
        "\r\n",
        "class BertClassifier():\r\n",
        "  def __init__(self, train_file_path, test_file_path, saved_model_path = transformer_model_path):\r\n",
        "    self.train_file_path = train_file_path\r\n",
        "    self.test_file_path = test_file_path\r\n",
        "\r\n",
        "    self.saved_model_path = saved_model_path\r\n",
        "    # assign their value based on const value defined in constants cell\r\n",
        "    self.train_size = TRAIN_SIZE\r\n",
        "    self.val_size = VAL_SIZE\r\n",
        "    self.test_size = TEST_SIZE\r\n",
        "\r\n",
        "    self.tfhub_handle_encoder = map_name_to_handle[bert_model_name]\r\n",
        "    self.tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\r\n",
        "    \r\n",
        "    self.model = None\r\n",
        "  \r\n",
        "  def build_classifier_model(self):\r\n",
        "    # string of inputs\r\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\r\n",
        "\r\n",
        "    # define chosen BERT preprocessor \r\n",
        "    preprocessing_layer = hub.KerasLayer(self.tfhub_handle_preprocess, name='preprocessing')\r\n",
        "    # get the output required for next layer by passing text_input \r\n",
        "    encoder_inputs = preprocessing_layer(text_input)\r\n",
        "    # now pass it to chosen encoder(which was recomended for sentiment analyses)\r\n",
        "    encoder = hub.KerasLayer(self.tfhub_handle_encoder, trainable=True, name='BERT_encoder')\r\n",
        "    # get the output of the BERT_encoder layer\r\n",
        "    outputs = encoder(encoder_inputs)\r\n",
        "    \r\n",
        "    net = outputs['pooled_output']\r\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\r\n",
        "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\r\n",
        "    \r\n",
        "    return tf.keras.Model(text_input, net)\r\n",
        "\r\n",
        "  def train(self, batch_size= 32, epochs= 5):\r\n",
        "    with open(self.train_file_path, 'rb') as train_file:\r\n",
        "      data = pickle.load(train_file)\r\n",
        "      train_ds = DataSequence(data['text'][:self.train_size], [0 if label == 0 else 1 for label in data['label'][:self.train_size]], batch_size)\r\n",
        "      val_ds = DataSequence(data['text'][self.train_size:self.train_size + self.val_size], [0 if label == 0 else 1 for label in data['label'][self.train_size:self.train_size + self.val_size]], batch_size)\r\n",
        "\r\n",
        "      loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\r\n",
        "      metrics = tf.metrics.BinaryAccuracy()\r\n",
        "\r\n",
        "      steps_per_epoch = train_ds.__len__()\r\n",
        "      num_train_steps = steps_per_epoch * epochs\r\n",
        "      num_warmup_steps = int(0.1*num_train_steps)\r\n",
        "\r\n",
        "      init_lr = 3e-5\r\n",
        "      optimizer = optimization.create_optimizer(init_lr=init_lr,\r\n",
        "                                                num_train_steps=num_train_steps,\r\n",
        "                                                num_warmup_steps=num_warmup_steps,\r\n",
        "                                                optimizer_type='adamw')\r\n",
        "\r\n",
        "      self.model = self.build_classifier_model()\r\n",
        "\r\n",
        "      self.model.compile(optimizer= optimizer,\r\n",
        "                              loss= loss,\r\n",
        "                              metrics= metrics)\r\n",
        "\r\n",
        "      self.model.fit(x= train_ds, epochs= epochs, validation_data= val_ds)\r\n",
        "\r\n",
        "      self.model.save(self.saved_model_path, include_optimizer=False)\r\n",
        "\r\n",
        "  def evaluate(self):\r\n",
        "    try: \r\n",
        "      if self.model is None:\r\n",
        "        self.model = tf.saved_model.load(self.saved_model_path)\r\n",
        "    except IOError:\r\n",
        "      print('-'*10, '\\t Classier model files do not exist, preparing them might take a while\\t', '-'*10)\r\n",
        "      self.train()\r\n",
        "      self.model = tf.saved_model.load(self.saved_model_path)\r\n",
        "\r\n",
        "    y_true = list()\r\n",
        "    loaded_y_pred = list()\r\n",
        "    with open(self.test_file_path, 'rb') as train_file:\r\n",
        "      test = pickle.load(train_file)\r\n",
        "      y_true = test['label'][:self.test_size]\r\n",
        "\r\n",
        "      prob_list = list()\r\n",
        "      for text in test['text'][:self.test_size]:\r\n",
        "        prob_list += list(tf.sigmoid(self.model(tf.constant([text]))).numpy()[0])\r\n",
        "\r\n",
        "      y_pred = [4 if p >=0.5 else 0 for p in prob_list]\r\n",
        "\r\n",
        "    report = classification_report(np.array(y_true), np.array(y_pred))\r\n",
        "    confusion_mat = confusion_matrix(np.array(y_true), np.array(y_pred))\r\n",
        "\r\n",
        "    return report, confusion_mat\r\n",
        "\r\n",
        "  def query(self, tweet):\r\n",
        "    prob = 0.0\r\n",
        "    try: \r\n",
        "      # load model\r\n",
        "      if self.model is None:\r\n",
        "        self.model = tf.saved_model.load(self.saved_model_path)\r\n",
        "      prob= list(tf.sigmoid(self.model(tf.constant([text_preprocessor(tweet)]))).numpy()[0])[0]\r\n",
        "\r\n",
        "    except IOError:\r\n",
        "      print('-'*10, '\\t Classier model files do not exist, preparing them might take a while\\t', '-'*10)\r\n",
        "      self.train()\r\n",
        "      # load model\r\n",
        "      if self.model is None:\r\n",
        "        self.model = tf.saved_model.load(self.saved_model_path)\r\n",
        "      prob= list(tf.sigmoid(self.model(tf.constant([text_preprocessor(tweet)]))).numpy()[0])[0]\r\n",
        "\r\n",
        "    if prob < 0.5:\r\n",
        "      return 'negative\\t{:.4f}'.format(prob)\r\n",
        "    else:\r\n",
        "      return 'positive\\t{:.4f}'.format(prob)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0Ouci6eK4RJ"
      },
      "source": [
        "### Train and Evaluate BERT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhgdPjalDhFI"
      },
      "source": [
        "* create an object from BertClassifier class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i_AjGgRgqEw"
      },
      "source": [
        "train = os.path.join(data_path, 'train.pickle')\r\n",
        "test = os.path.join(data_path, 'test.pickle')\r\n",
        "bert_model = BertClassifier(train, test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2gsr69yJQ7q"
      },
      "source": [
        "* represent model layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "k0qR-YvHInu8",
        "outputId": "0d0d5b8a-b553-490d-cee9-6ccb1ff83d20"
      },
      "source": [
        "tf.keras.utils.plot_model(bert_model.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF3WilYFDmr6"
      },
      "source": [
        "* train bert_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpSq8wRCib-y",
        "outputId": "9b86ec61-baf2-42f3-897e-f1cff69b41fd"
      },
      "source": [
        "bert_model.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2500/2500 [==============================] - 2493s 991ms/step - loss: 0.5538 - binary_accuracy: 0.7056 - val_loss: 0.4665 - val_binary_accuracy: 0.7704\n",
            "Epoch 2/5\n",
            "2500/2500 [==============================] - 2534s 1s/step - loss: 0.4422 - binary_accuracy: 0.7869 - val_loss: 0.5041 - val_binary_accuracy: 0.7648\n",
            "Epoch 3/5\n",
            "2500/2500 [==============================] - 2546s 1s/step - loss: 0.3700 - binary_accuracy: 0.8310 - val_loss: 0.5085 - val_binary_accuracy: 0.7753\n",
            "Epoch 4/5\n",
            "2500/2500 [==============================] - 2544s 1s/step - loss: 0.3027 - binary_accuracy: 0.8691 - val_loss: 0.5959 - val_binary_accuracy: 0.7790\n",
            "Epoch 5/5\n",
            "2500/2500 [==============================] - 2542s 1s/step - loss: 0.2497 - binary_accuracy: 0.8958 - val_loss: 0.6663 - val_binary_accuracy: 0.7749\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 900). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 900). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTO9UajwDqPT"
      },
      "source": [
        "* evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7poplmaaJga",
        "outputId": "d5791c40-74ca-40e7-d929-37c85599fa0f"
      },
      "source": [
        "report, matrix = bert_model.evaluate()\r\n",
        "print(report, '\\n', matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79     10217\n",
            "           4       0.79      0.76      0.77      9783\n",
            "\n",
            "    accuracy                           0.78     20000\n",
            "   macro avg       0.78      0.78      0.78     20000\n",
            "weighted avg       0.78      0.78      0.78     20000\n",
            " \n",
            " [[8230 1987]\n",
            " [2353 7430]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddu5iOCfDtXH"
      },
      "source": [
        "* get result of bert_model on query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye6I1_9pfaOk",
        "outputId": "11cac6e2-61ab-48ae-870d-07ea72328d6f"
      },
      "source": [
        "tweet = 'safe ways to heal your #acne!! #altwaystoheal #healthy #healing!!'\r\n",
        "# result = f'input: {tweet:<30} : class: {svm_model.query(tweet))}'\r\n",
        "print('{0:<100s}{1:10s}{2:>10s}'.format(tweet,'',bert_model.query(tweet)))\r\n",
        "\r\n",
        "tweet = 'the next school year is the year for can\\'t think about that #school #exams #hate'\r\n",
        "# result = f'input: {tweet:<30} : class: {svm_model.query(tweet))}'\r\n",
        "\r\n",
        "print('{0:<100s}{1:10s}{2:>10s}'.format(tweet,'',bert_model.query(tweet)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "safe ways to heal your #acne!! #altwaystoheal #healthy #healing!!                                             positive\t0.8998\n",
            "the next school year is the year for can't think about that #school #exams #hate                              negative\t0.1209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfRoJWT2EMD1"
      },
      "source": [
        "# All Together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5GZynlBeD6z"
      },
      "source": [
        "* Define both Linear and Bert Classifier sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAx5EaW1kqsn"
      },
      "source": [
        "train_data_path = os.path.join(data_path, 'train.pickle')\r\n",
        "test_data_path = os.path.join(data_path, 'test.pickle')\r\n",
        "\r\n",
        "linear_classifier_sample = LinearClassifier(train_data_path, test_data_path)\r\n",
        "bert_classifier_sample = BertClassifier(train_data_path, test_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaiI0J93d2qo"
      },
      "source": [
        "### See performanse on some raw tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRzA3S65ERv9",
        "outputId": "22ab13c7-ea95-458a-9e4a-bea1052d29a3"
      },
      "source": [
        "sample_raw_tweets= ['The Life is cool. But not for Me. ',\r\n",
        " \"I'm missing you babe..  but as long as your alive I'm happy.. Yawwwnn.. I'm tired my love imma try to sleep hopefully you had a headstart\",\r\n",
        " 'Crazy wind today = no birding  http://ff.im/1XTTi', 'Is not going to sleep tonite. ', \r\n",
        " '@labelsnotlove   my home town. My mammy called all depressd.  Pls explain y a parent let their 8yr old child walk alone? Hello? Its 2009!',\r\n",
        "  \"@jokerrrr It stillllll hasn't arrived \",\r\n",
        " \"@a5hleyf i'm spending time with my grandma early tomorrow and i can't leave skittles by herself. \",\r\n",
        " '@ScoutBuck tons no hay Troll? ahhhh ',  \r\n",
        " '@alejandralei i dont think i can cause its my cousins birthday party ',\r\n",
        " 'have watched that considering today. yaknow. shawnna tomomorrow;i need my bestfriend ', '@shandasaurus  I see.',\r\n",
        " '@phlaimeaux where are you? ', '@thousand_miles no ',\r\n",
        " \"@hannahsix cream for his eye and he may have herpes - not ocular herpes, but a different strain.    He's doing okay though.\",\r\n",
        " \"It's going to be a long year for A's fans. \", '@AmberPacific i know i dont know why i said that ',\r\n",
        " 'Almost through with my Italian homework!  Weeeeee.... now if I only understood what I was doing.  ',\r\n",
        " \"@t_wolfe  i miss u too. i'm totally comin back tho! Lastnight was sooooooo much fun!\",\r\n",
        " 'Argh, got up early for Girls Aloud on Freshly Squeezed and it was just the video ',\r\n",
        " '@_saffron  Why not? :[', 'At mobilityvic.org launch.  No grog  nice video from PWC though',\r\n",
        " '@ourcitylight that was so sudden!! ', 'bedtime. wake up call at 7am ', \"@almostcool i'm off now \", \r\n",
        " '@ekim1406 hehehe too bad they were separated ', '@DanielCalderonL yeaah I hate that! ',\r\n",
        " \"I'm going to love this season of the hills... I can tell!  Spartans sucked.    Goodnight!!\",\r\n",
        " \"@NeYawn Yeah! Interview... Don't know even when it is... \",\r\n",
        " '@garretjiroux do u write back on twitter? i miss ya garee...  x', \"@zaibatsu ME...I'm up.  \",\r\n",
        " \"Almost finished with new moon.... If I didn't have to work tomorrow I would totally finish it tonight! Geez... \",\r\n",
        " \"@pilvlp My luck I'd probably get stopped by a cop or something stupid!  \", \r\n",
        " '@SukottoXD I saw ice in the rain today. Not quite snow, but frozen water, nonetheless. ',\r\n",
        " 'has realized that twitter is getting more attention from her mama then she is....hahaha  LAME!',\r\n",
        " 'whoa im super hungry  Life cereal w/granola &amp; raspberries is calling my name',\r\n",
        " \"Really let down by gossip girl...it's all I have to make my Mondays good and all they give are reruns... \",\r\n",
        " \"They don't get hyphy on the east coast  ...even to E40\", 'No rain please ',\r\n",
        " 'No TravoRadio this morning. BlipFM is down. ', '@PrinceDavey aww no invite??  lol jk. coolness for the day off!',\r\n",
        " \"Note to you all: don't go to the choclate bar @ schiphol!! it is passengers only \", 'on the coach  gonna be fun!'\r\n",
        " ]\r\n",
        "\r\n",
        "first = True\r\n",
        "for tweet in sample_raw_tweets:\r\n",
        "    linear_pred = linear_classifier_sample.query(tweet)\r\n",
        "    bert_pred = bert_classifier_sample.query(tweet)\r\n",
        "    if first:\r\n",
        "      print('{0:<140s}  |  {1:>10s}  |  {2:>10s}\\t'.format('raw tweets text', 'Linear pred', 'Bert pred'))\r\n",
        "      print('-' * 180)\r\n",
        "\r\n",
        "      first = False\r\n",
        "    print('{0:<140s}  |  {1:>10s}  |  {2:>10s}\\t'.format(tweet, linear_pred, bert_pred))\r\n",
        "    print('-' * 180)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw tweets text                                                                                                                               |  Linear pred  |   Bert pred\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "The Life is cool. But not for Me.                                                                                                             |    negative  |  negative\t0.4184\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "I'm missing you babe..  but as long as your alive I'm happy.. Yawwwnn.. I'm tired my love imma try to sleep hopefully you had a headstart     |    negative  |  negative\t0.4849\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Crazy wind today = no birding  http://ff.im/1XTTi                                                                                             |    posetive  |  negative\t0.4010\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Is not going to sleep tonite.                                                                                                                 |    posetive  |  negative\t0.4865\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@labelsnotlove   my home town. My mammy called all depressd.  Pls explain y a parent let their 8yr old child walk alone? Hello? Its 2009!     |    negative  |  negative\t0.4671\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@jokerrrr It stillllll hasn't arrived                                                                                                         |    negative  |  negative\t0.4849\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@a5hleyf i'm spending time with my grandma early tomorrow and i can't leave skittles by herself.                                              |    negative  |  negative\t0.4152\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@ScoutBuck tons no hay Troll? ahhhh                                                                                                           |    negative  |  negative\t0.4078\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@alejandralei i dont think i can cause its my cousins birthday party                                                                          |    negative  |  negative\t0.4933\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "have watched that considering today. yaknow. shawnna tomomorrow;i need my bestfriend                                                          |    posetive  |  negative\t0.4537\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@shandasaurus  I see.                                                                                                                         |    posetive  |  negative\t0.4000\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@phlaimeaux where are you?                                                                                                                    |    posetive  |  negative\t0.4912\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@thousand_miles no                                                                                                                            |    posetive  |  negative\t0.4912\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@hannahsix cream for his eye and he may have herpes - not ocular herpes, but a different strain.    He's doing okay though.                   |    negative  |  negative\t0.4762\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "It's going to be a long year for A's fans.                                                                                                    |    posetive  |  negative\t0.4647\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@AmberPacific i know i dont know why i said that                                                                                              |    negative  |  negative\t0.4616\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Almost through with my Italian homework!  Weeeeee.... now if I only understood what I was doing.                                              |    negative  |  negative\t0.4634\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@t_wolfe  i miss u too. i'm totally comin back tho! Lastnight was sooooooo much fun!                                                          |    posetive  |  negative\t0.4489\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Argh, got up early for Girls Aloud on Freshly Squeezed and it was just the video                                                              |    posetive  |  negative\t0.4082\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@_saffron  Why not? :[                                                                                                                        |    negative  |  negative\t0.4324\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "At mobilityvic.org launch.  No grog  nice video from PWC though                                                                               |    posetive  |  negative\t0.4879\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@ourcitylight that was so sudden!!                                                                                                            |    negative  |  negative\t0.4211\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "bedtime. wake up call at 7am                                                                                                                  |    posetive  |  negative\t0.4065\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@almostcool i'm off now                                                                                                                       |    posetive  |  negative\t0.4912\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@ekim1406 hehehe too bad they were separated                                                                                                  |    negative  |  negative\t0.4692\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@DanielCalderonL yeaah I hate that!                                                                                                           |    negative  |  negative\t0.4568\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "I'm going to love this season of the hills... I can tell!  Spartans sucked.    Goodnight!!                                                    |    posetive  |  negative\t0.4318\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@NeYawn Yeah! Interview... Don't know even when it is...                                                                                      |    negative  |  negative\t0.4257\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@garretjiroux do u write back on twitter? i miss ya garee...  x                                                                               |    posetive  |  negative\t0.4677\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@zaibatsu ME...I'm up.                                                                                                                        |    posetive  |  negative\t0.4912\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Almost finished with new moon.... If I didn't have to work tomorrow I would totally finish it tonight! Geez...                                |    negative  |  negative\t0.4407\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@pilvlp My luck I'd probably get stopped by a cop or something stupid!                                                                        |    negative  |  negative\t0.4322\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@SukottoXD I saw ice in the rain today. Not quite snow, but frozen water, nonetheless.                                                        |    negative  |  negative\t0.4752\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "has realized that twitter is getting more attention from her mama then she is....hahaha  LAME!                                                |    negative  |  negative\t0.4963\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "whoa im super hungry  Life cereal w/granola &amp; raspberries is calling my name                                                              |    posetive  |  negative\t0.4702\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Really let down by gossip girl...it's all I have to make my Mondays good and all they give are reruns...                                      |    posetive  |  negative\t0.4240\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "They don't get hyphy on the east coast  ...even to E40                                                                                        |    negative  |  negative\t0.4025\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "No rain please                                                                                                                                |    negative  |  negative\t0.4430\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "No TravoRadio this morning. BlipFM is down.                                                                                                   |    posetive  |  negative\t0.4678\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "@PrinceDavey aww no invite??  lol jk. coolness for the day off!                                                                               |    posetive  |  negative\t0.4803\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Note to you all: don't go to the choclate bar @ schiphol!! it is passengers only                                                              |    posetive  |  negative\t0.4059\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "on the coach  gonna be fun!                                                                                                                   |    posetive  |  negative\t0.4980\t\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EP-yDLfiY9X"
      },
      "source": [
        "### Get a tweet text and  get result of both classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfup1A0xiX2C",
        "outputId": "d1ab5643-0ffe-4c9f-d830-7004ed57894c"
      },
      "source": [
        "tweet = input('Enter a Tweet text\\t')\r\n",
        "linear_pred = linear_classifier_sample.query(tweet)\r\n",
        "bert_pred = bert_classifier_sample.query(tweet)\r\n",
        "print('-' * 41)\r\n",
        "print('|\\t{0:>10s}  |  {1:>10s}\\t|'.format('Bert pred', bert_pred))\r\n",
        "print('-' * 41)\r\n",
        "'it was not that bad'\r\n",
        "print('|\\t{0:>10s}  |  {1:>10s}\\t|'.format('Linear pred', linear_pred))\r\n",
        "print('-' * 41)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a Tweet text\t'it was not that bad'\n",
            "-----------------------------------------\n",
            "|\t Bert pred  |  positive\t0.9393\t|\n",
            "-----------------------------------------\n",
            "|\tLinear pred  |    negative\t|\n",
            "-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}